import tensorflow as tffrom keras.layers import Input, Lambda, Dense, Flattenfrom keras.models import Modelfrom keras.applications.vgg16 import VGG16from keras.applications.vgg16 import preprocess_inputfrom keras.preprocessing import imagefrom keras.preprocessing.image import ImageDataGeneratorfrom keras.models import Sequentialimport numpy as npfrom glob import globimport matplotlib.pyplot as plt# re-size all the images to thisIMAGE_SIZE = [224, 224]     # VGG16 image size is 224 * 224train_path = 'Datasets/Train'valid_path = 'Datasets/Test'vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)     # Remove VGG16 last layer# IMAGE_SIZE + [3] = IMAGE_SIZE + number of channels# include_top = False -> Last layer is going to be deleted# don't train existing weights because it is already trainedfor layer in vgg.layers:    layer.trainable = False # Useful for getting number of classesfolders = glob('Datasets/Train/*')  # Number of categoris we have in last layer# How many folders are present inside dataset# Out layers - you can add more if you wantx = Flatten()(vgg.output)prediction = Dense(len(folders), activation='softmax')(x)# Appending my folders as a Dense layer with the softmax activation function with this particular x value# create a model objectmodel = Model(inputs=vgg.input, outputs=prediction)# View the structure of the modelmodel.summary()# tell the model what cost and optimization mehthod to usemodel.compile(    loss='categorical_crossentropy',    optimizer='adam',    metrics=['accuracy'])train_datagen = ImageDataGenerator(rescale = 1./255,                                   shear_range = 0.2,                                   zoom_range = 0.2,                                   horizontal_flip = True)test_datagen = ImageDataGenerator(rescale = 1./255)training_set = train_datagen.flow_from_directory('Datasets/Train',                                                 target_size = (224, 224),                                                 batch_size = 32,                                                 class_mode = 'categorical')test_set = test_datagen.flow_from_directory('Datasets/Test',                                            target_size = [224, 224],                                            batch_size = 32,                                            class_mode = 'categorical')'''r = model.fit_generator(training_set,                        sampes_per_epoch=8000,                        validation_data = test_set,                        nb_val_sample = 2000)'''# fit the modelr = model.fit_generator(training_set,                        validation_data=test_set,                        epochs = 5,                        steps_per_epoch=len(training_set),                        validation_steps = len(test_set))r.history# Lossplt.plot(r.history['loss'], label='train loss')# plt.plot(r.history['val_loss'], label='val loss')plt.legend()plt.show()plt.savefig('LossVal_loss')# Accuraciesplt.plot(r.history['accuracy'], label='val acc')plt.legendplt.show()plt.savefig('accVal_acc')import tensorflow as tffrom keras.models import load_datamodel.save('facefeatures_new_model.h5')